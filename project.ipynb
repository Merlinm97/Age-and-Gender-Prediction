{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MTCNN face detector\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models for age and gender detection\n",
    "age_weights = \"age_net.caffemodel\"\n",
    "age_config = \"age_deploy.prototxt\"\n",
    "age_net = cv2.dnn.readNet(age_weights, age_config)\n",
    "\n",
    "gender_weights = \"gender_net.caffemodel\"\n",
    "gender_config = \"gender_deploy.prototxt\"\n",
    "gender_net = cv2.dnn.readNet(gender_weights, gender_config)\n",
    "\n",
    "# Model parameters\n",
    "age_list = ['(0-5)', '(6-10)', '(11-15)', '(16-20)', '(21-30)', '(31-45)', '(46-60)', '(61-80)', '(81-100)']\n",
    "gender_list = ['Male', 'Female']\n",
    "model_mean = (104, 117, 123)\n",
    "\n",
    "# Load and process the image\n",
    "image_path = r\"E:\\OPEN CV PROJECT\\Age and Gender Project-Open CV\\images\\images (4).jpeg\"\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Image not found or unable to read the image.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to RGB for MTCNN\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect faces using MTCNN\n",
    "faces = detector.detect_faces(img_rgb)\n",
    "\n",
    "if len(faces) == 0:\n",
    "    print(\"No faces detected.\")\n",
    "    exit()\n",
    "\n",
    "# Process each detected face\n",
    "for face in faces:\n",
    "    x, y, w, h = face['box']  # Extract bounding box\n",
    "    x, y = max(0, x), max(0, y)  # Ensure coordinates are within bounds\n",
    "    x1, y1 = x + w, y + h\n",
    "    x1, y1 = min(img.shape[1], x1), min(img.shape[0], y1)\n",
    "\n",
    "    # Expand the bounding box to include hair and a bit of surrounding area\n",
    "    margin = int(0.2 * h)  # 20% of the height as margin\n",
    "    x = max(0, x - margin)\n",
    "    y = max(0, y - margin)\n",
    "    x1 = min(img.shape[1], x1 + margin)\n",
    "    y1 = min(img.shape[0], y1 + margin)\n",
    "\n",
    "    # Crop the face\n",
    "    face_img = img[y:y1, x:x1]\n",
    "\n",
    "    # Check if the cropped face is valid\n",
    "    if face_img.size == 0:\n",
    "        print(\"Error: Cropped face is invalid.\")\n",
    "        continue\n",
    "\n",
    "    # Resize the face to the input size required by the model\n",
    "    try:\n",
    "        face_resized = cv2.resize(face_img, (227, 227))\n",
    "    except Exception as e:\n",
    "        print(f\"Error resizing face: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Normalize pixel values\n",
    "    blob = cv2.dnn.blobFromImage(face_resized, 1.0, (227, 227), model_mean, swapRB=False, crop=False)\n",
    "    \n",
    "    # Predict gender\n",
    "    gender_net.setInput(blob)\n",
    "    gender_preds = gender_net.forward()\n",
    "    gender = gender_list[np.argmax(gender_preds[0])]\n",
    "\n",
    "    # Predict age\n",
    "    age_net.setInput(blob)\n",
    "    age_preds = age_net.forward()\n",
    "    age = age_list[np.argmax(age_preds[0])]\n",
    "\n",
    "    # Annotate the image\n",
    "    label = f\"{gender}, {age}\"\n",
    "    text_scale = 0.5  # Reduced text scale\n",
    "    text_thickness = 1  # Reduced thickness\n",
    "    text_color = (0, 255, 0)\n",
    "\n",
    "    # Adjust the position to ensure visibility\n",
    "    y_text = y - 10 if y - 10 > 10 else y + 10\n",
    "    cv2.rectangle(img, (x, y), (x1, y1), (255, 0, 0), 2)\n",
    "    cv2.putText(img, label, (x, y_text), cv2.FONT_HERSHEY_SIMPLEX, text_scale, text_color, text_thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the annotated image only\n",
    "cv2.imshow(\"Age and Gender Detection\", img)\n",
    "\n",
    "# Wait for 3 seconds and then close the window automatically\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "# Ensure the window closes properly\n",
    "if cv2.getWindowProperty(\"Age and Gender Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
